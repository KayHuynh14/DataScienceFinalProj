{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Predicting Airplane Delays\n",
    "\n",
    "The goals of this notebook are:\n",
    "- Process and create a dataset from downloaded ZIP files\n",
    "- Exploratory data analysis (EDA)\n",
    "- Establish a baseline model and improve it\n",
    "\n",
    "## Introduction to business scenario\n",
    "You work for a travel booking website that is working to improve the customer experience for flights that were delayed. The company wants to create a feature to let customers know if the flight will be delayed due to weather when the customers are booking the flight to or from the busiest airports for domestic travel in the US. \n",
    "\n",
    "You are tasked with solving part of this problem by leveraging machine learning to identify whether the flight will be delayed due to weather. You have been given access to the a dataset of on-time performance of domestic flights operated by large air carriers. You can use this data to train a machine learning model to predict if the flight is going to be delayed for the busiest airports.\n",
    "\n",
    "### Dataset\n",
    "The provided dataset contains scheduled and actual departure and arrival times reported by certified US air carriers that account for at least 1 percent of domestic scheduled passenger revenues. The data was collected by the Office of Airline Information, Bureau of Transportation Statistics (BTS). The dataset contains date, time, origin, destination, airline, distance, and delay status of flights for flights between 2014 and 2018.\n",
    "The data are in 60 compressed files, where each file contains a CSV for the flight details in a month for the five years (from 2014 - 2018). The data can be downloaded from this link: [https://ucstaff-my.sharepoint.com/:f:/g/personal/ibrahim_radwan_canberra_edu_au/Er0nVreXmihEmtMz5qC5kVIB81-ugSusExPYdcyQTglfLg?e=bNO312]. Please download the data files and place them on a relative path. Dataset(s) used in this assignment were compiled by the Office of Airline Information, Bureau of Transportation Statistics (BTS), Airline On-Time Performance Data, available with the following link: [https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare the environment \n",
    "\n",
    "Use one of the labs which we have practised on with the Amazon Sagemakers where you perform the following steps:\n",
    "1. Start a lab.\n",
    "2. Create a notebook instance and name it \"oncloudproject\".\n",
    "3. Increase the used memory to 25 GB from the additional configurations.\n",
    "4. Open Jupyter Lab and upload this notebook into it.\n",
    "5. Upload the two combined CVS files (combined_csv_v1.csv and combined_csv_v2.csv), which you created in Part A of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Build and evaluate simple models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use linear learner estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey and to comments on the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code here and add cells as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to split data into train, validate and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset combined_csv_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data= pd.read_csv(\"combined_csv_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('target', axis=1)\n",
    "y=data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline logistic regression model\n",
    "classifier1 = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "classifier1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier1.predict(X_test)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_scores = classifier1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model using accuracy as the metric\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "In this section, you'll evaluate your trained model on test data and report on the following metrics:\n",
    "* Confusion Matrix plot\n",
    "* Plot the ROC\n",
    "* Report statistics such as Accuracy, Percision, Recall, Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a plot of the confusion matrix, and various scoring metrics, create a couple of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    # complete the code here\n",
    "    cm = confusion_matrix(test_labels, target_predicted)\n",
    "    cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "    sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc(test_labels, target_predicted):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, target_predicted, pos_label=2)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To plot the confusion matrix, call the `plot_confusion_matrix` function on the `test_labels` and `target_predicted` data from your batch job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print statistics and plot an ROC curve, call the `plot_roc` function on the `test_labels` and `target_predicted` data from your batch job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plot_roc(y_test, y_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset combined_csv_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data= pd.read_csv(\"combined_csv_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('target', axis=1)\n",
    "y=data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline logistic regression model\n",
    "classifier1 = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "classifier1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier1.predict(X_test)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_scores = classifier1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model using accuracy as the metric\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "In this section, you'll evaluate your trained model on test data and report on the following metrics:\n",
    "* Confusion Matrix plot\n",
    "* Plot the ROC\n",
    "* Report statistics such as Accuracy, Percision, Recall, Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a plot of the confusion matrix, and various scoring metrics, create a couple of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    # complete the code here\n",
    "    cm = confusion_matrix(test_labels, target_predicted)\n",
    "    cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "    sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc(test_labels, target_predicted):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, target_predicted, pos_label=2)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To plot the confusion matrix, call the `plot_confusion_matrix` function on the `test_labels` and `target_predicted` data from your batch job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print statistics and plot an ROC curve, call the `plot_roc` function on the `test_labels` and `target_predicted` data from your batch job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plot_roc(y_test, y_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final comments here and turn the cell type into markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build and evaluate ensembe models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use xgboost estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "6. write down your observation on the difference between the performance of using the simple and ensemble models.\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset combined_csv_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import warnings, requests, zipfile, io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data= pd.read_csv(\"combined_csv_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and testing sets (70% - 15% - 15%)\n",
    "train, test_and_validate = train_test_split(data, test_size=0.2, random_state=42, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, validate = train_test_split(test_and_validate, test_size=0.5, random_state=42, stratify=test_and_validate['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['target'].value_counts())\n",
    "print(test['target'].value_counts())\n",
    "print(validate['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c94466a2114430l5163277t1w714773806955-labbucket-1thzohtf7px1s'\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_file='combinedv1_train.csv'\n",
    "test_file='combinedv1_test.csv'\n",
    "validate_file='combinedv1_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False)\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"auc\",\n",
    "             \"objective\": \"binary:logistic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hosting the model\n",
    "Now that you have a trained model, you can host it by using Amazon SageMaker hosting services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                serializer = sagemaker.serializers.CSVSerializer(),\n",
    "                instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing predictions\n",
    "Now that you have a deployed model, you will run some predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have 31 instances, with seven attributes. The first five instances are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = test.iloc[0:1,1:]\n",
    "row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_csv_buffer = io.StringIO()\n",
    "row.to_csv(batch_X_csv_buffer, header=False, index=False)\n",
    "test_row = batch_X_csv_buffer.getvalue()\n",
    "print(test_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the data to perform a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.predict(test_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result you get isn't a *0* or a *1*. Instead, you get a *probability score*. You can apply some conditional logic to the probability score to determine if the answer should be presented as a 0 or a 1. You will work with this process when you do batch predictions.\n",
    "\n",
    "For now, compare the result with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminating the deployed model\n",
    "To delete the endpoint, use the **delete_endpoint** function on the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a batch transform\n",
    "\n",
    "When you are in the training-testing-feature engineering cycle, you want to test your holdout or test sets against the model. You can then use those results to calculate metrics. You could deploy an endpoint as you did earlier, but then you must remember to delete the endpoint. However, there is a more efficient way.\n",
    "\n",
    "You can use the transformer method of the model to get a transformer object. You can then use the transform method of this object to perform a prediction on the entire test dataset. SageMaker will: \n",
    "\n",
    "- Spin up an instance with the model\n",
    "- Perform a prediction on all the input values\n",
    "- Write those values to Amazon Simple Storage Service (Amazon S3) \n",
    "- Finally, terminate the instance\n",
    "\n",
    "You will start by turning your data into a CSV file that the transformer object can take as input. This time, you will use **iloc** to get all the rows, and all columns *except* the first column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = test.iloc[:,1:];\n",
    "batch_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write your data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, before you perform a transform, configure your transformer with the input file, output location, and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the transform completes, you can download the results from Amazon S3 and compare them with the input.\n",
    "\n",
    "First, download the output from Amazon S3 and load it into a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=',',names=['class'])\n",
    "target_predicted.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a function to convert the probabilty into either a *0* or a *1*.\n",
    "\n",
    "The first table output will be the *predicted values*, and the second table output is the *original test data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_convert(x):\n",
    "    threshold = 0.65\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted['binary'] = target_predicted['class'].apply(binary_convert)\n",
    "\n",
    "print(target_predicted.head(10))\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset combined_csv_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data_v2 = pd.read_csv(\"combined_csv_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and testing sets (70% - 15% - 15%)\n",
    "train_v2, test_and_validate_v2 = train_test_split(data_v2, test_size=0.2, random_state=42, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2, validate_v2 = train_test_split(test_and_validate_v2, test_size=0.5, random_state=42, stratify=test_and_validate_v2['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_v2.shape)\n",
    "print(test_v2.shape)\n",
    "print(validate_v2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_v2['target'].value_counts())\n",
    "print(test_v2['target'].value_counts())\n",
    "print(validate_v2['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c94466a2114430l5163277t1w714773806955-labbucket-1thzohtf7px1s'\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_v2_file='combinedv2_train.csv'\n",
    "test_v2_file='combinedv2_test.csv'\n",
    "validate_v2_file='combinedv2_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False)\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_s3_csv(train_v2_file, 'train', train)\n",
    "upload_s3_csv(test_v2_file, 'test', test)\n",
    "upload_s3_csv(validate_v2_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"auc\",\n",
    "             \"objective\": \"binary:logistic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model_v2=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v2_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_v2_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_v2_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_v2_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_v2_channels = {'train': train_channel, 'validation': validate_v2_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_v2.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hosting the model\n",
    "Now that you have a trained model, you can host it by using Amazon SageMaker hosting services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                serializer = sagemaker.serializers.CSVSerializer(),\n",
    "                instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing predictions\n",
    "Now that you have a deployed model, you will run some predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have 31 instances, with seven attributes. The first five instances are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = test.iloc[0:1,1:]\n",
    "row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_csv_buffer = io.StringIO()\n",
    "row.to_csv(batch_X_csv_buffer, header=False, index=False)\n",
    "test_row = batch_X_csv_buffer.getvalue()\n",
    "print(test_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the data to perform a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.predict(test_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result you get isn't a *0* or a *1*. Instead, you get a *probability score*. You can apply some conditional logic to the probability score to determine if the answer should be presented as a 0 or a 1. You will work with this process when you do batch predictions.\n",
    "\n",
    "For now, compare the result with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminating the deployed model\n",
    "To delete the endpoint, use the **delete_endpoint** function on the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a batch transform\n",
    "\n",
    "When you are in the training-testing-feature engineering cycle, you want to test your holdout or test sets against the model. You can then use those results to calculate metrics. You could deploy an endpoint as you did earlier, but then you must remember to delete the endpoint. However, there is a more efficient way.\n",
    "\n",
    "You can use the transformer method of the model to get a transformer object. You can then use the transform method of this object to perform a prediction on the entire test dataset. SageMaker will: \n",
    "\n",
    "- Spin up an instance with the model\n",
    "- Perform a prediction on all the input values\n",
    "- Write those values to Amazon Simple Storage Service (Amazon S3) \n",
    "- Finally, terminate the instance\n",
    "\n",
    "You will start by turning your data into a CSV file that the transformer object can take as input. This time, you will use **iloc** to get all the rows, and all columns *except* the first column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = test.iloc[:,1:];\n",
    "batch_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write your data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, before you perform a transform, configure your transformer with the input file, output location, and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the transform completes, you can download the results from Amazon S3 and compare them with the input.\n",
    "\n",
    "First, download the output from Amazon S3 and load it into a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=',',names=['class'])\n",
    "target_predicted.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a function to convert the probabilty into either a *0* or a *1*.\n",
    "\n",
    "The first table output will be the *predicted values*, and the second table output is the *original test data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_convert(x):\n",
    "    threshold = 0.65\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted['binary'] = target_predicted['class'].apply(binary_convert)\n",
    "\n",
    "print(target_predicted.head(10))\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final comments here and turn the cell type into markdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
